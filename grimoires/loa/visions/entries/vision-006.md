# Vision 006: Symbiotic Layer — Convergence Detection & Intent Modeling

## Source
- Issue: #344, Comments 3-6
- Author: @zkSoju (soju+loa operator)
- Session: 2026-02-15 orchestration philosophy debrief

## Insight

There is a missing layer between adversarial review (Flatline) and implementation (Run Mode). Current Loa layers:

- **Flatline**: Adversarial review — stress-tests artifacts
- **Bridgebuilder**: Persona/identity — shapes how agents think
- **Hounfour**: Model routing — which model runs where
- **??? (Missing)**: Symbiotic layer — agent models operator's evolving intent in real-time

The symbiotic layer would:
1. Track operator's **clarity state** (fuzzy → sharp) across a session
2. Detect when intent crystallizes and match agent precision accordingly
3. Reduce translation loss between what the operator means and what agents do
4. Know when to deploy Flatline (artifact exists) vs when to co-think (vision forming)

Key distinction: "Rip this apart" → Flatline council. "Help me think" → Symbiotic mode. These are fundamentally different interaction patterns.

## Multi-Mind Extension

The symbiotic layer extends beyond operator↔agent to team-scale:

| Translation | Current | Needed |
|-------------|---------|--------|
| Operator → Agent | Instructions → execution (lossy) | Intent modeling |
| Researcher → Builder | Papers → issues (averaged) | Context relationship preservation |
| Mind → Mind (via tool) | Summarization (flattened) | Cognitive style bridging |

The success metric isn't "did the agent understand?" — it's "did the *receiver* understand what the *sender* meant, through the tool?"

## Connection

"The bridge is the product." The framework doesn't need Neuralink-level shared understanding. It needs to keep closing the gap — each iteration preserving more of the original thinker's structure. This connects to the Hounfour rider/horse metaphor: the rider's intent should sharpen the horse's behavior over time, not just direct it.

FAANG parallel: Google's PAIR (People + AI Research) work on "AI-mediated communication" explores the same territory — how AI can preserve rather than flatten the structure of human thought.
