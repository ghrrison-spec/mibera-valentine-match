# =============================================================================
# Loa Framework Configuration Examples
# =============================================================================
# This file contains comprehensive configuration examples for .loa.config.yaml
# Copy sections you need to your .loa.config.yaml file.
#
# For documentation on each option, see:
# - .claude/loa/reference/config-reference.md
# - CHANGELOG.md for version-specific features
# =============================================================================

# -----------------------------------------------------------------------------
# Ride Configuration (v1.31.0)
# -----------------------------------------------------------------------------
# Controls /ride codebase analysis behavior.
ride:
  # Days before ride artifacts are considered stale. When /ride is invoked
  # and .reality-meta.json shows artifacts younger than this, the user is
  # prompted to skip or re-analyze. Use --fresh flag to bypass.
  staleness_days: 7

  # Enrichment phases (v1.39.0) — opt-in depth for /ride
  # These phases run after the standard ride when --with-gaps, --with-decisions,
  # --with-terms, or --enriched flags are passed. No flags = standard ride unchanged.
  enrichment:
    gaps:
      # Maximum open gaps before error. Prevents gap tracker from growing unbounded.
      max_open: 200
      # Warning threshold. Logs a warning when open gaps reach this count.
      warn_at: 150
    decisions:
      # Months before an ADR is flagged as stale and recommended for reconfirmation.
      stale_months: 12
      # Additional ADR directory paths to scan (beyond the 5 built-in patterns).
      extra_paths: []
    terminology:
      # Maximum terms to extract from source code. Ranked by frequency, capped here.
      max_terms: 50

# -----------------------------------------------------------------------------
# Configurable Paths (v1.27.0)
# -----------------------------------------------------------------------------
# Customize grimoire and state file locations. All paths are relative to
# PROJECT_ROOT. Useful for OpenClaw integration or custom project structures.
#
# Requirements:
# - yq v4+ (mikefarah/yq) for YAML parsing
# - Paths must be relative (no leading /)
# - Soul source and output must be different files
paths:
  # Grimoire directory (default: grimoires/loa)
  # All derived paths (ledger, notes, trajectory, etc.) are relative to this
  grimoire: grimoires/loa

  # Beads directory (default: .beads)
  beads: .beads

  # Soul file paths (BEAUVOIR.md -> SOUL.md transformation)
  soul:
    source: grimoires/loa/BEAUVOIR.md   # Input template
    output: grimoires/loa/SOUL.md       # Generated output

# OpenClaw Integration Example:
# Place SOUL.md at workspace root for OpenClaw bootstrap
# paths:
#   grimoire: .loa/grimoire
#   soul:
#     source: .loa/grimoire/BEAUVOIR.md
#     output: SOUL.md    # At workspace root

  # State directory (default: .loa-state) — v2.0.0
  # Consolidated state zone: beads, ck, run, memory, trajectory
  # All scripts use get_state_*() getters from path-lib.sh
  state_dir: .loa-state

# Environment Variable Overrides (updated for state-dir):
# - LOA_STATE_DIR: Override state directory path
# - LOA_ALLOW_ABSOLUTE_STATE=1: Allow absolute paths for state_dir (containers/CI)
# - LOA_GRIMOIRE_DIR: Override grimoire path
# - LOA_BEADS_DIR: Override beads path
# - LOA_SOUL_SOURCE: Override soul source path
# - LOA_SOUL_OUTPUT: Override soul output path
# - LOA_USE_LEGACY_PATHS=1: Bypass config, use hardcoded defaults
# - LOA_STRICT_CONFIG=1: Fail on missing yq (default: warn and use defaults)

# -----------------------------------------------------------------------------
# Plan and Analyze (v1.6.0)
# -----------------------------------------------------------------------------
plan_and_analyze:
  codebase_grounding:
    enabled: true
    reality_staleness_days: 7
    ride_timeout_minutes: 20
    skip_on_ride_error: false

# -----------------------------------------------------------------------------
# Interview Depth Configuration (v1.41.0)
# -----------------------------------------------------------------------------
# Controls question depth, input style, and pacing across planning skills.
# Default: thorough mode with sequential plain-text discovery questions.
#
# Construct override: Schema supports future construct manifest interview
# overrides gated by trust tier (RFC #379). Not wired yet.
interview:
  # Mode: thorough | minimal
  #   thorough: 3-6 questions/phase, mandatory phase gates, no inference
  #   minimal: 1-2 questions/phase, skip covered phases, faster throughput
  mode: thorough

  # Per-skill overrides (optional — mode applies to all if omitted)
  # per_skill:
  #   discovering-requirements: thorough
  #   designing-architecture: minimal
  #   planning-sprints: thorough

  # Input style — per interaction type
  input_style:
    # routing_gates: AskUserQuestion for phase transitions (Continue/Adjust/Stop)
    routing_gates: structured    # structured | plain
    # discovery_questions: plain text for domain exploration
    discovery_questions: plain   # structured | plain
    # confirmation: AskUserQuestion for understanding checks
    confirmation: structured     # structured | plain

  # Question pacing
  #   sequential: one question per turn, wait for response (default for thorough)
  #   batch: 3-6 numbered questions per turn, user responds freely
  pacing: sequential   # sequential | batch

  # Phase transition gates
  phase_gates:
    between_phases: true       # Require confirmation between discovery phases
    before_generation: true    # Require confirmation before generating output doc

  # Backpressure controls (anti-rushing for capable models)
  backpressure:
    no_infer: true             # Prohibit inferring answers to unasked questions
    show_work: true            # Cite known vs unknown before asking
    min_confirmation_questions: 1  # Min questions even for "covered" phases

# -----------------------------------------------------------------------------
# Autonomous Agent (v1.11.0)
# -----------------------------------------------------------------------------
autonomous_agent:
  operator:
    type: auto  # auto | human | ai
  audit_threshold: 4
  max_remediation_loops: 3
  context:
    soft_limit_tokens: 80000
    hard_limit_tokens: 150000

# -----------------------------------------------------------------------------
# Update Configuration (v1.39.0)
# -----------------------------------------------------------------------------
# Controls /update-loa behavior including supply chain verification.
# update:
#   # Override remote URL allowlist for forks/mirrors (default: 0xHoneyJar/loa)
#   allowed_remotes:
#     - "https://github.com/your-org/loa.git"
#     - "git@github.com:your-org/loa.git"

# -----------------------------------------------------------------------------
# Workspace Cleanup (v1.23.0)
# -----------------------------------------------------------------------------
# Archives previous cycle artifacts when starting fresh /simstim or /autonomous
workspace_cleanup:
  enabled: true                        # Enable workspace cleanup in preflight

  # Default action when no TTY (non-interactive mode)
  # Options: archive | skip
  default_action: archive

  # Disk space safety settings
  disk_space:
    safety_margin: 2                   # Require 2x archive size free space

  # Lock settings for concurrent execution prevention
  lock:
    ttl_seconds: 300                   # Lock timeout for stale detection

  # Security settings
  security:
    follow_symlinks: false             # Never follow symlinks (security)

  # Archive retention policy
  retention:
    max_age_days: 90                   # Delete archives older than 90 days
    max_count: 10                      # Keep only 10 newest archives
    # Note: Archives with .keep marker are never deleted

  # Prompt settings (for interactive mode)
  prompt:
    timeout_seconds: 5                 # Timeout before defaulting to archive

# -----------------------------------------------------------------------------
# Goal Traceability (v0.21.0)
# -----------------------------------------------------------------------------
goal_traceability:
  enabled: true              # Enable goal ID system
  require_goal_ids: false    # Require G-N IDs in PRD (backward compat)
  auto_assign_ids: true      # Auto-assign if missing
  generate_appendix_c: true  # Generate goal mapping in sprint
  generate_e2e_task: true    # Auto-generate E2E validation task

goal_validation:
  enabled: true              # Enable goal validation
  block_on_at_risk: false    # Block review on AT_RISK (default: warn)
  block_on_blocked: true     # Block review on BLOCKED
  require_e2e_task: true     # Require E2E task in final sprint

# -----------------------------------------------------------------------------
# Effort Parameter (v1.13.0)
# -----------------------------------------------------------------------------
effort:
  default_level: medium
  budget_ranges:
    low: { min: 1024, max: 4000 }
    medium: { min: 8000, max: 16000 }
    high: { min: 24000, max: 32000 }
  per_skill:
    auditing-security: high
    designing-architecture: high
    implementing-tasks: medium
    translating-for-executives: low

# -----------------------------------------------------------------------------
# Context Editing (v1.13.0)
# -----------------------------------------------------------------------------
context_editing:
  enabled: true
  compact_threshold_percent: 80
  preserve_recent_turns: 5
  clear_targets:
    - stale_tool_results
    - completed_phase_details
    - superseded_file_reads
  preserve_artifacts:
    - trajectory_events
    - quality_gate_results
    - decision_records

# -----------------------------------------------------------------------------
# Memory Schema (v1.13.0)
# -----------------------------------------------------------------------------
memory_schema:
  enabled: true
  storage_dir: grimoires/loa/memory
  auto_capture:
    decisions: true
    errors: true
    learnings: true
  retrieval:
    max_per_query: 10
    min_confidence: 0.6
  lifecycle:
    auto_archive: true
    check_on_session_start: true

# -----------------------------------------------------------------------------
# Skills (v1.14.0)
# -----------------------------------------------------------------------------
skills:
  defer_loading: false        # Config prep only (runtime Phase 2)
  always_load:
    - autonomous-agent
    - run-mode
  categories:
    planning: [discovering-requirements, planning-sprints, designing-architecture]
    implementation: [implementing-tasks, deploying-infrastructure]
    quality: [reviewing-code, auditing-security]
    support: [translating-for-executives, continuous-learning]
    operations: [autonomous-agent, run-mode, riding-codebase, mounting-framework]

# -----------------------------------------------------------------------------
# Learnings / Two-Tier Architecture (v1.15.1)
# -----------------------------------------------------------------------------
learnings:
  tiers:
    framework:
      enabled: true
      weight: 1.0
    project:
      enabled: true
      weight: 0.9
  query:
    default_tier: all  # framework | project | all
    max_results: 10

# -----------------------------------------------------------------------------
# Oracle (v1.11.0)
# -----------------------------------------------------------------------------
oracle:
  weights:
    loa: 1.0
    anthropic: 0.8
    community: 0.5
  query:
    default_indexer: auto  # auto | qmd | grep
    default_limit: 10
    default_scope: all

# -----------------------------------------------------------------------------
# Compound Learning (v1.10.0, Flatline Integration v1.23.0)
# -----------------------------------------------------------------------------
compound_learning:
  enabled: true
  pattern_detection:
    min_occurrences: 2
    similarity_threshold: 0.6
  quality_gates:
    discovery_depth: { min_score: 5 }
    reusability: { min_score: 5 }

  # Flatline Integration (v1.23.0)
  # Connect Flatline Protocol multi-model consensus to Compound Learning
  flatline_integration:
    # Master toggle for Flatline → Compound Learning connection
    enabled: true

    # Capture learning candidates from Flatline HIGH_CONSENSUS outputs
    capture_from_flatline:
      enabled: true
      min_consensus_score: 750      # Minimum consensus score (0-1000)
      include_disputed: true         # Also capture low-delta disputed items
      disputed_max_delta: 200        # Maximum score delta for disputed items

    # Transformation configuration (content → trigger/solution)
    transformation:
      fallback_to_llm: true          # Use LLM when patterns fail
      max_transformations_per_cycle: 50  # Prevent runaway API costs

    # Validation of borderline learnings (Sprint 2)
    validation:
      enabled: true
      borderline_range: [20, 28]     # Score range for borderline (out of 40)
      max_validations_per_cycle: 10  # Budget control
      rate_limit_seconds: 30         # Minimum time between validations

    # Upstream proposal enhancement (Sprint 3)
    upstream_enhancement:
      semantic_similarity:
        enabled: true
        threshold: 70                # Similarity threshold (0-100)
        alpha: 0.6                   # Weight for semantic vs Jaccard
        combine_with_jaccard: true
      pre_proposal_review:
        enabled: true
        min_alignment_score: 600     # Minimum alignment (0-1000)

  # API configuration for Flatline integration
  api:
    max_retries: 3
    initial_backoff_ms: 1000
    max_backoff_ms: 30000
    timeout_seconds: 60
    circuit_breaker:
      failure_threshold: 5
      reset_timeout_seconds: 300

  # LLM response validation
  validation:
    llm_responses:
      require_schema_validation: true
      sanitize_input: true
      sanitize_output: true
      banned_tokens:
        - "ignore previous"
        - "disregard instructions"
        - "system prompt"

  # Budget controls (SKP-001)
  budget:
    daily_budget_cents: 500          # Maximum daily API spend
    warn_at_percent: 80              # Warning threshold
    track_costs_in_trajectory: true

  # Security and data redaction (SKP-006)
  security:
    redaction:
      enabled: true
      patterns:
        - api_keys
        - emails
        - file_paths
      allowlist_domains: []

# -----------------------------------------------------------------------------
# Visual Communication (v2.0.0)
# -----------------------------------------------------------------------------
visual_communication:
  enabled: true
  mode: "github"   # github (default) | render | url
  theme: "github"  # github|dracula|nord|tokyo-night|solarized-light|solarized-dark|catppuccin

  # Local rendering options (for mode: render)
  local_render:
    output_format: "svg"  # svg | png
    output_dir: "grimoires/loa/diagrams/"

  # Legacy URL options (for mode: url)
  service: "https://agents.craft.do/mermaid"  # External service URL
  include_preview_urls: false  # Generate preview links (legacy)

# -----------------------------------------------------------------------------
# Agent Browser (v2.0.0)
# -----------------------------------------------------------------------------
agent_browser:
  enabled: false              # Opt-in (default: false)
  tool: "dev-browser"         # MCP server to use
  mode: "headless"            # headless | extension
  session_persistence: true   # Keep sessions between calls
  screenshot_dir: "grimoires/loa/screenshots/"
  timeout_ms: 30000           # Navigation timeout

# -----------------------------------------------------------------------------
# Prompt Enhancement (v1.14.0 + Invisible Mode v1.17.0)
# -----------------------------------------------------------------------------
prompt_enhancement:
  enabled: true
  auto_enhance_threshold: 4
  show_analysis: true
  max_refinement_iterations: 3

  # Invisible mode: automatically enhance prompts without user visibility
  invisible_mode:
    enabled: true              # Enable invisible enhancement for all commands
    log_to_trajectory: true    # Log activity to trajectory for debugging
    timeout_ms: 500            # Maximum time for enhancement (advisory)

  # Middleware configuration
  middleware:
    enabled: true              # Enable middleware mode (enhancement before skill)
    exclude_skills:            # Skills excluded from enhancement
      - "enhancing-prompts"    # Prevent recursion
      - "run-mode"             # Don't enhance autonomous mode
    exclude_commands: []       # Additional commands to exclude

# -----------------------------------------------------------------------------
# URL Registry (v1.15.1)
# -----------------------------------------------------------------------------
url_registry:
  enabled: true
  placeholder_domain: your-domain.example.com
  warn_on_missing: true

# -----------------------------------------------------------------------------
# Feedback Routing (v1.11.0)
# -----------------------------------------------------------------------------
feedback:
  routing:
    enabled: true           # Enable smart routing
    auto_classify: true     # Auto-detect target repo
    require_confirmation: true  # Always confirm with user

    # Construct routing (v1.40.0 / cycle-025)
    # Routes feedback about installed construct packs/skills to their source repos.
    # Requires constructs to declare source_repo in manifest.yaml.
    construct_routing:
      enabled: true               # Master toggle for construct feedback routing
      attribution_threshold: 0.33 # Minimum confidence to suggest construct routing (0.0-1.0)
      redaction:
        strip_absolute_paths: true   # Redact /home/user/... paths
        strip_secrets: true          # Redact AWS keys, tokens, JWTs
        strip_env_vars: true         # Redact environment variable assignments
        include_snippets: false      # Code blocks stripped for external repos (default: off)
        include_file_refs: true      # File references kept but paths made relative
        include_environment: false   # Environment/system info section stripped (default: off)
      rate_limits:
        per_repo_daily: 5           # Warn after N issues to same repo in 24h
        per_repo_daily_hard: 20     # Block at N issues to same repo in 24h
        dedup_window_hours: 24      # Fingerprint dedup window in hours

  labels:
    graceful_missing: true  # Don't fail on missing labels

# -----------------------------------------------------------------------------
# Update Loa / Branch Testing (v1.11.0)
# -----------------------------------------------------------------------------
update_loa:
  branch_testing:
    enabled: true
    feature_patterns: ["feature/*", "fix/*", "topic/*", "wip/*", "test/*"]
    test_branch_prefix: "test/loa-"

# -----------------------------------------------------------------------------
# Run Mode
# -----------------------------------------------------------------------------
run_mode:
  enabled: true
  defaults:
    max_cycles: 20
    timeout_hours: 8
  sprint_plan:
    branch_prefix: "feature/"
    default_branch_name: "release"
    consolidate_pr: true
    commit_prefix: "feat"
    include_commits_by_sprint: true
  # Git operations control (v1.30.0)
  # Controls automatic push and PR creation at end of /run execution
  git:
    # auto_push: Controls whether to push commits to remote
    #   - true: Push and create PR automatically (default, current behavior)
    #   - false: Never auto-push, keep all changes local
    #   - prompt: Ask before pushing (HITL confirmation)
    # Can be overridden with --local (forces false) or --confirm-push (forces prompt)
    auto_push: true
    # Always create PRs as drafts - this is hardcoded and cannot be changed
    create_draft_pr: true

# -----------------------------------------------------------------------------
# BUTTERFREEZONE — Agent-Grounded README (v1.35.0)
# -----------------------------------------------------------------------------
# Generates BUTTERFREEZONE.md: a provenance-tagged, checksum-verified,
# token-efficient project summary for AI agent consumption.
# "The zone where only truth survives — no butter, no hype."
butterfreezone:
  enabled: true                         # On by default, opt-out via false
  output_path: BUTTERFREEZONE.md        # Relative to repo root
  word_budget:
    total: 3200                         # ~8000 tokens (model-agnostic)
    per_section: 800                    # ~2000 tokens per section
  staleness_days: 7                     # Advisory freshness window
  hooks:
    run_bridge: true                    # Regenerate in bridge FINALIZING phase
    run_sprint_plan: false              # Phase 2: regenerate after sprint plan
    post_merge: false                   # Phase 2: regenerate on merge to main
    ride: false                         # Future: regenerate after /ride
    ship: false                         # Phase 2: regenerate on /ship
  rtfm:
    check_enabled: true                 # Include in RTFM validation
    strict_mode: false                  # false=advisory warnings, true=hard gate
  ecosystem:                              # Cross-repo discovery graph (v1.40.0)
    # Each entry declares a related repository with its role and interface.
    # Agents traverse these links to build a multi-repo capability graph.
    # Schema per entry:
    #   repo (required):     GitHub slug — machine-resolvable via gh
    #   role (required):     semantic relationship (runtime, protocol, distribution, billing, client, library)
    #   interface (required): integration surface (hounfour-router, npm-package, jwt-auth, etc.)
    #   protocol (optional): shared contract version from a common package
    - repo: 0xHoneyJar/loa-finn
      role: runtime
      interface: hounfour-router
      protocol: loa-hounfour@4.6.0
    - repo: 0xHoneyJar/loa-hounfour
      role: protocol
      interface: npm-package
      protocol: loa-hounfour@4.6.0
    - repo: 0xHoneyJar/arrakis
      role: distribution
      interface: jwt-auth
      protocol: loa-hounfour@4.6.0
  culture:                                # Cultural BUTTERFREEZONE (v1.40.0)
    # Optional section communicating project principles, naming, methodology.
    # Provenance: OPERATIONAL. Omitted when not configured.
    naming_etymology: "Vodou terminology as cognitive hooks for framework concepts"
    principles:
      - "Think Before Coding — plan and analyze before implementing"
      - "Simplicity First — minimum complexity for the current task"
    methodology: "Agent-driven development with iterative excellence loops"
  manual_sections:
    sentinel_start: "<!-- manual-start -->"
    sentinel_end: "<!-- manual-end -->"
  # Capability overrides — manual adjustments to inferred capabilities (v1.40.0)
  # The generator infers capabilities from SKILL.md keyword analysis. These
  # overrides let you suppress false positives or add capabilities the
  # inference engine cannot detect.
  capability_overrides:
    # Suppress: list of strings to remove from inferred capabilities.
    # Uses grep -Fv (fixed-string, case-sensitive, substring match).
    # A value of "ci" removes ANY capability line containing "ci"
    # (e.g., "ci-deploy" but also "specificity-analysis").
    # Values are NOT regexes — special characters are treated literally.
    suppress: []
    # Examples:
    #   suppress:
    #     - "network: read"           # Remove inferred network read capability
    #     - "model: invoke"           # Remove inferred model invocation
    #
    # Add: list of capability strings to force-include.
    # add: []
    # Examples:
    #   add:
    #     - "filesystem: write (scope: app)"
  security:
    redaction_enabled: true             # Gitleaks-pattern secret redaction

# -----------------------------------------------------------------------------
# Beads-First Infrastructure (v1.29.0)
# -----------------------------------------------------------------------------
# Task tracking via beads_rust (br) is the EXPECTED DEFAULT.
# Working without beads is treated as an abnormal state requiring explicit
# acknowledgment. "We're building spaceships. Safety is paramount."
beads:
  # Mode: required | recommended | disabled
  # - required: Block workflow if beads unavailable
  # - recommended: Prompt for opt-out if unavailable (default)
  # - disabled: No beads checks
  mode: recommended

  # Health check frequency
  # - session: Once per session start
  # - sprint: At sprint boundaries (default)
  # - phase: At every workflow phase
  health_check_frequency: sprint

  # Opt-out configuration (for users without beads installed)
  opt_out:
    # Hours until opt-out expires and user must re-acknowledge
    confirmation_interval_hours: 24
    # Require reason when opting out
    require_reason: true
    # Maximum consecutive opt-outs before warning
    max_consecutive: 3

  # Autonomous mode configuration
  autonomous:
    # Require beads for /run and /autonomous workflows
    requires_beads: true
    # Allow DEGRADED status to proceed (warn only)
    allow_degraded: true
    # Maximum recovery attempts before halting
    max_recovery_attempts: 3

  # Size and staleness thresholds
  thresholds:
    # Warn when issues.jsonl exceeds this size
    jsonl_warn_size_mb: 50
    # Warn when beads.db exceeds this size
    db_warn_size_mb: 100
    # Warn when JSONL hasn't been synced in this many hours
    sync_stale_hours: 24

# -----------------------------------------------------------------------------
# Hounfour Multi-Model Provider Abstraction (v1.31.0)
# -----------------------------------------------------------------------------
# Configure upstream model routing, pricing, budget enforcement, and circuit
# breakers. System defaults ship in .claude/defaults/model-config.yaml —
# only override values you want to change here.
#
# Architecture: SDD §4.1.2 (Config Schema), §4.2 (Routing), §4.5 (Metering)
# Feature flags and metering — Hounfour Model-Heterogeneous Agent Routing
hounfour:
  # Top-level flag — controls whether Flatline uses Hounfour routing
  # or the legacy direct-call path. Set to true when ready to migrate.
  flatline_routing: false

  # Per-subsystem feature flags (all default true — opt-out, not opt-in)
  feature_flags:
    google_adapter: true     # Enable Google provider adapter
    deep_research: true      # Enable Deep Research models (Interactions API)
    flatline_routing: false   # Route Flatline through Hounfour
    metering: true           # Enable BudgetEnforcer cost tracking
    thinking_traces: true    # Include thinking config in request bodies
    jam_geometry: false      # Enable Jam multi-model parallel review (opt-in)
    context_filtering: false # Epistemic context filtering: false | "audit" | "enforce"

  # Metering — cost tracking and budget enforcement (SDD §4.3)
  metering:
    enabled: true
    ledger_path: .run/cost-ledger.jsonl      # JSONL append-only cost ledger
    budget:
      daily_micro_usd: 500000000             # $500/day (500M micro-USD)
      warn_at_percent: 80                    # Warn when spending exceeds this %
      on_exceeded: downgrade                 # block | downgrade | warn

  # Provider registry — override endpoints, auth, or add new providers
  # Providers not listed here use system defaults from model-config.yaml
  providers:
    openai:
      # type: openai                    # Provider SDK type
      # endpoint: "https://api.openai.com/v1"
      auth: "{env:OPENAI_API_KEY}"      # Auth template (env: prefix resolves env vars)
      models:
        gpt-5.2:
          capabilities: [chat, tools, function_calling]
          context_window: 128000
          pricing:
            input_per_mtok: 10000000    # $10.00/M tokens (integer micro-USD)
            output_per_mtok: 30000000   # $30.00/M tokens
        gpt-5.3-codex:
          capabilities: [chat, tools, function_calling, code]
          context_window: 400000
          pricing:
            input_per_mtok: 1750000     # $1.75/M tokens
            output_per_mtok: 14000000   # $14.00/M tokens

    google:
      # type: google                    # Provider SDK type
      # endpoint: "https://generativelanguage.googleapis.com/v1beta"
      auth: "{env:GOOGLE_API_KEY}"      # Requires GOOGLE_API_KEY environment variable
      models:
        gemini-2.5-flash:
          capabilities: [chat]
          context_window: 1048576
          pricing:
            input_per_mtok: 150000      # $0.15/M tokens (integer micro-USD)
            output_per_mtok: 600000     # $0.60/M tokens
        gemini-2.5-pro:
          capabilities: [chat, thinking_traces]
          context_window: 1048576
          pricing:
            input_per_mtok: 1250000     # $1.25/M tokens
            output_per_mtok: 10000000   # $10.00/M tokens

    anthropic:
      auth: "{env:ANTHROPIC_API_KEY}"
      models:
        claude-opus-4-6:
          capabilities: [chat, tools, function_calling, thinking_traces]
          context_window: 200000
          pricing:
            input_per_mtok: 5000000     # $5.00/M tokens
            output_per_mtok: 25000000   # $25.00/M tokens
        claude-sonnet-4-6:
          capabilities: [chat, tools, function_calling]
          context_window: 200000
          pricing:
            input_per_mtok: 3000000
            output_per_mtok: 15000000

  # Flatline tertiary model — enables 3-model triangular cross-scoring
  # Requires GOOGLE_API_KEY to be set in environment
  flatline_tertiary_model: gemini-2.5-pro  # 3-model Flatline: Opus + GPT-5.3-codex + Gemini

  # Aliases — short names mapping to provider:model-id
  aliases:
    native: "claude-code:session"         # Reserved — Claude Code native runtime
    reviewer: "openai:gpt-5.2"            # Primary review model
    reasoning: "openai:gpt-5.2"           # Reasoning/skeptic model
    cheap: "anthropic:claude-sonnet-4-6"  # Budget-conscious model
    opus: "anthropic:claude-opus-4-6"     # High-quality model

  # Agent bindings — which model each agent uses + requirements
  # Agents not listed here use the system defaults from model-config.yaml
  agents:
    reviewing-code:
      model: reviewer
      temperature: 0.3
    translating-for-executives:
      model: cheap
      temperature: 0.5
    flatline-reviewer:
      model: reviewer
      temperature: 0.3
    flatline-skeptic:
      model: reasoning
      temperature: 0.5
      requires:
        thinking_traces: preferred
    # Agents bound to native runtime (Claude Code session):
    # implementing-tasks, riding-codebase, designing-architecture,
    # planning-sprints, discovering-requirements, auditing-security

  # Routing — fallback chains (provider down) and downgrade chains (budget)
  routing:
    fallback:
      openai: [anthropic]               # OpenAI down → try Anthropic
      anthropic: [openai]               # Anthropic down → try OpenAI
    downgrade:
      reviewer: [cheap]                 # Budget exceeded → downgrade

    # Circuit breaker — per-provider state machine (CLOSED/OPEN/HALF_OPEN)
    # State files: .run/circuit-breaker-{provider}.json
    circuit_breaker:
      failure_threshold: 5              # Consecutive failures to trip OPEN
      reset_timeout_seconds: 60         # Seconds in OPEN before probing
      half_open_max_probes: 1           # Concurrent probes in HALF_OPEN
      count_window_seconds: 300         # Rolling window for failure count

  # Retry — per-request retry with exponential backoff
  retry:
    max_retries: 3                      # Per-provider retries
    max_total_attempts: 6               # Global hard cap (SDD §4.2.7)
    max_provider_switches: 2            # Maximum fallback chain depth
    base_delay_seconds: 1.0             # Exponential backoff base

  # Metering — JSONL cost ledger with integer micro-USD arithmetic
  metering:
    enabled: true
    ledger_path: "grimoires/loa/a2a/cost-ledger.jsonl"
    budget:
      daily_micro_usd: 500000000        # $500/day (500M micro-USD)
      warn_at_percent: 80               # Warn at 80% of daily budget
      on_exceeded: downgrade            # downgrade | block | warn

  # Timeouts — per-provider connection/read/write limits
  defaults:
    connect_timeout: 10                 # seconds
    read_timeout: 120                   # seconds
    write_timeout: 30                   # seconds

# Hounfour Examples:
#
# Example 1: Conservative (all native, no remote calls)
# hounfour:
#   flatline_routing: false
#   agents:
#     reviewing-code:
#       model: native
#     flatline-reviewer:
#       model: native
#
# Example 2: Budget-conscious (lower daily limit, aggressive downgrade)
# hounfour:
#   metering:
#     budget:
#       daily_micro_usd: 50000000       # $50/day
#       warn_at_percent: 60
#       on_exceeded: block              # Hard stop instead of downgrade
#
# Example 3: Custom provider (e.g., Azure OpenAI)
# hounfour:
#   providers:
#     azure-openai:
#       type: openai
#       endpoint: "https://myorg.openai.azure.com/openai/deployments/gpt-5"
#       auth: "{env:AZURE_OPENAI_KEY}"
#       models:
#         gpt-5-azure:
#           capabilities: [chat, tools, function_calling]
#           pricing:
#             input_per_mtok: 10000000
#             output_per_mtok: 30000000
#   aliases:
#     reviewer: "azure-openai:gpt-5-azure"

# -----------------------------------------------------------------------------
# Persistent Memory (v1.28.0)
# -----------------------------------------------------------------------------
# Session-spanning observation storage with progressive disclosure.
# Captures learnings, discoveries, and decisions for cross-session recall.
# See: grimoires/loa/memory/README.md
memory:
  # Master toggle
  enabled: true

  # Capture settings
  capture:
    discoveries: true       # Capture code discoveries
    errors: true           # Capture error-solution pairs
    decisions: true        # Capture architecture decisions
    patterns: true         # Capture recurring patterns

  # Storage limits
  max_observations: 10000  # Maximum observations before archiving oldest
  retention_days: 90       # Archive observations older than this

  # Progressive disclosure levels
  disclosure:
    index_tokens: 50       # Tokens per entry in index mode
    summary_tokens: 200    # Tokens per entry in summary mode
    full_tokens: 500       # Tokens for full observation

  # Hook configuration
  hooks:
    post_tool: true        # Capture from PostToolUse hook
    learning_signals:      # Patterns that trigger capture
      - "discovered"
      - "learned"
      - "fixed"
      - "resolved"
      - "pattern"
      - "insight"

  # Privacy
  privacy:
    redact_sensitive: true # Redact content with <private> tags
    exclude_tools:         # Tools to never capture from
      - Read
      - Glob
      - Grep

# -----------------------------------------------------------------------------
# Trajectory Archive (v2.0.0 / cycle-038)
# -----------------------------------------------------------------------------
trajectory:
  archive:
    # Maximum export size in MB before LFS warning
    max_export_size_mb: 50
    # Auto-compress exports (gzip)
    compress: true
    # Opt-in: commit trajectory exports to git
    git_commit: false
    # Retention: delete exports older than this many days
    retention_days: 365

# -----------------------------------------------------------------------------
# Memory Bootstrap (v2.0.0 / cycle-038)
# -----------------------------------------------------------------------------
memory_bootstrap:
  # Sources for deterministic bootstrap
  sources:
    trajectory: true
    flatline: true
    feedback: true
    bridge: true
  # Quality gates
  quality:
    min_confidence: 0.7
    min_content_length: 10
    dedup: true

# -----------------------------------------------------------------------------
# Redaction Pipeline (v2.0.0 / cycle-038)
# -----------------------------------------------------------------------------
redaction:
  # Fail-closed by default
  strict: true
  # Operator override allowlist file (one pattern per line)
  # allowlist_file: .loa-redact-allowlist
  # Override specific rules (for known false positives)
  override_rules: []
  # Input limits
  max_input_size_mb: 50
  # Entropy detection threshold (Shannon bits/char)
  entropy_threshold: 4.5
  entropy_min_length: 20

# -----------------------------------------------------------------------------
# Migration (v2.0.0 / cycle-038)
# -----------------------------------------------------------------------------
migration:
  # Compatibility mode: auto | resolution | symlink | copy
  compat_mode: auto
  # Lock timeout in seconds
  lock_timeout: 30

# -----------------------------------------------------------------------------
# Destructive Command Guard (v1.28.0)
# -----------------------------------------------------------------------------
# Runtime safety layer that validates shell commands before execution.
# Intercepts potentially dangerous operations and applies configurable policies.
# See: .claude/protocols/destructive-command-guard.md
destructive_command_guard:
  # Master toggle - set to true to enable DCG
  enabled: true

  # Timeout for pattern matching (milliseconds)
  timeout_ms: 100

  # Security packs to load (core is always loaded)
  # Each pack adds domain-specific patterns
  packs:
    # Database operations (SQL, MongoDB, Redis)
    database: true
    # Docker/container operations
    docker: true
    # Kubernetes operations (kubectl, helm)
    kubernetes: false
    # AWS CLI operations
    cloud-aws: false
    # Google Cloud operations
    cloud-gcp: false
    # Azure CLI operations
    cloud-azure: false
    # Terraform/OpenTofu operations
    terraform: false

  # Additional safe paths beyond defaults
  # Paths must be absolute or use environment variables
  safe_paths:
    - "${PROJECT_ROOT}/tmp"
    - "${PROJECT_ROOT}/cache"
    # Add project-specific paths here
    # - /app/cache

  # Override default actions for specific patterns
  # Useful for relaxing rules in specific contexts
  overrides:
    # Example: Allow git push --force with warning instead of block
    # git_push_force:
    #   action: WARN
    #   reason: "Team workflow allows force push to feature branches"

  # Run Mode integration
  run_mode:
    # Enable DCG during autonomous execution
    enabled: true
    # Log blocked commands to trajectory
    audit_log: true
    # Halt workflow after N blocked commands
    halt_on_block_count: 3

# -----------------------------------------------------------------------------
# Simstim - HITL Accelerated Development (v1.24.0)
# -----------------------------------------------------------------------------
# Orchestrate complete development cycle (PRD → SDD → Sprint → Implementation)
# with Flatline Protocol reviews at each stage. Human drives planning phases
# while HIGH_CONSENSUS findings auto-integrate.
# "Experience the AI's work while maintaining your own consciousness." — Gibson
simstim:
  # Master toggle - set to true to enable /simstim command
  enabled: true

  # Flatline behavior in HITL mode
  flatline:
    auto_accept_high_consensus: true   # Auto-integrate without prompting
    show_disputed: true                # Present DISPUTED items for decision
    show_blockers: true                # Present BLOCKERS (NOT auto-halt like autonomous)
    phases:                            # Which phases get Flatline review
      - prd
      - sdd
      - sprint

  # Default options
  defaults:
    timeout_hours: 24                  # Maximum workflow duration

  # Phase skipping behavior
  skip_phases:
    prd_if_exists: false               # Still review even if PRD exists
    sdd_if_exists: false               # Still review even if SDD exists
    sprint_if_exists: false            # Still review even if sprint exists

# -----------------------------------------------------------------------------
# Search Orchestration (v1.7.0)
# -----------------------------------------------------------------------------
prefer_ck: true  # Use ck when available

# -----------------------------------------------------------------------------
# Upstream Learning Flow (v1.17.0)
# -----------------------------------------------------------------------------
upstream_detection:
  enabled: true
  min_occurrences: 3
  min_success_rate: 0.8
  min_upstream_score: 70

upstream_proposals:
  target_repo: "0xHoneyJar/loa"
  label: "learning-proposal"
  anonymization:
    enabled: true
  rejection_cooldown_days: 90

# -----------------------------------------------------------------------------
# Input Guardrails & Danger Level Enforcement (v1.20.0)
# -----------------------------------------------------------------------------
# Pre-execution validation for skill invocations. Provides PII filtering,
# injection detection, and relevance checking before skills execute.
# Based on OpenAI's "A Practical Guide to Building Agents" guardrails pattern.
guardrails:
  # Input guardrails (pre-execution)
  input:
    enabled: true

    # PII Filter: Detect and redact sensitive data before processing
    # Actions: redact (replace with placeholder), anonymize (generic value)
    pii_filter:
      enabled: true
      mode: blocking              # blocking | parallel | advisory
      patterns:
        api_keys: true            # sk-*, ghp_*, AKIA*
        emails: true              # user@example.com
        phone_numbers: true       # 555-123-4567
        ssn: true                 # 123-45-6789
        credit_cards: true        # 4111-1111-1111-1111
        jwt_tokens: true          # eyJ... tokens
        private_keys: true        # -----BEGIN PRIVATE KEY-----
        file_paths: anonymize     # anonymize | redact | ignore
      log_redactions: true        # Log redaction count (never values)

    # Injection Detection: Check for prompt injection patterns
    # Score threshold: 0.0-1.0 (higher = more strict)
    injection_detection:
      enabled: true
      mode: blocking
      threshold: 0.7              # Range: 0.0-1.0 (default: 0.7)
      patterns:
        - instruction_override    # "ignore previous", "disregard"
        - role_confusion          # "you are now", "act as"
        - context_manipulation    # "system prompt", "debug mode"
        - encoding_evasion        # base64, unicode tricks

    # Relevance Check: Verify request matches skill purpose
    # Note: High false positive rate - recommended mode: advisory or parallel
    relevance_check:
      enabled: false              # Disabled by default (high FP rate)
      mode: advisory
      confidence_threshold: 0.8   # Range: 0.0-1.0 (default: 0.8)

  # Tripwire: Halt execution on parallel guardrail failure
  tripwire:
    enabled: true
    on_failure: halt              # halt | warn | log
    rollback_on_halt: false       # Revert uncommitted changes (experimental)

  # Danger Level Enforcement: Tool risk classification
  # Levels: safe, moderate, high, critical
  danger_level:
    enforce: true
    interactive:
      safe: execute               # Execute immediately
      moderate: execute_with_notice  # Brief notice in output
      high: confirm_required      # Require explicit confirmation
      critical: confirm_with_reason  # Confirm + explain why
    autonomous:
      safe: execute               # Execute immediately
      moderate: execute_with_log  # Execute with enhanced logging
      high: block_without_flag    # BLOCK unless --allow-high
      critical: always_block      # ALWAYS BLOCK (no override)

  # Trajectory logging for guardrail events
  logging:
    enabled: true
    input_guardrails: true
    danger_level_decisions: true
    handoffs: true
    redaction_audit: true         # Log redaction counts for audit

# -----------------------------------------------------------------------------
# Invisible Retrospective Learning (v1.19.0)
# -----------------------------------------------------------------------------
# Automatic learning detection during skill execution without user invocation.
# Uses skill postludes to silently scan for discoveries and extract learnings.
# Mirrors the invisible prompt enhancement pattern from v1.17.0.
invisible_retrospective:
  # Master toggle - set to false to disable all invisible retrospective
  enabled: true

  # Always log to trajectory (even when disabled) - useful for debugging
  log_to_trajectory: true

  # Minimum quality gates passed to surface finding (out of 4)
  # Gates: Depth, Reusability, Trigger Clarity, Verification
  # Range: 0-4 (0 = surface everything, 4 = maximum strictness)
  surface_threshold: 3

  # Maximum candidates to evaluate per skill invocation
  # Range: 1-20 (recommended max: 10, higher values increase processing time)
  max_candidates: 5

  # Maximum learnings to extract per session (prevents noise)
  # Range: 1-10 (recommended max: 5, higher values may flood NOTES.md)
  max_extractions_per_session: 3

  # Sanitize descriptions before logging (redacts API keys, paths, emails, etc.)
  # CRITICAL: Do NOT disable in production - defense in depth applies sanitization even if false
  sanitize_descriptions: true

  # Per-skill enablement (only skills with postludes support this)
  skills:
    implementing-tasks: true     # High discovery potential (bugs, debugging)
    auditing-security: true      # Security patterns and findings
    reviewing-code: true         # Code review insights
    deploying-infrastructure: false  # Lower discovery potential
    designing-architecture: false    # Lower discovery potential

  # Quality gate toggles (all default to true)
  # Disable specific gates if they're too strict for your use case
  quality_gates:
    require_depth: true          # Gate 1: Discovery required multiple steps
    require_reusability: true    # Gate 2: Generalizable beyond this instance
    require_trigger_clarity: true # Gate 3: Clear when to apply learning
    require_verification: true   # Gate 4: Solution confirmed working

# -----------------------------------------------------------------------------
# Flatline Protocol (v1.17.0)
# -----------------------------------------------------------------------------
# Multi-model adversarial review using Claude Opus 4.6 + GPT-5.2 for planning
# document quality assurance. Phase 1: parallel reviews, Phase 2: cross-scoring,
# Phase 3: consensus extraction with HIGH/DISPUTED/LOW/BLOCKER classification.
flatline_protocol:
  # Master toggle - set to true to enable Flatline Protocol
  enabled: true

  # Auto-trigger after planning phases (prd, sdd, sprint)
  auto_trigger: true

  # Phase-specific toggles
  phases:
    prd: true      # Review after /plan-and-analyze
    sdd: true      # Review after /architect
    sprint: true   # Review after /sprint-plan

  # Model configuration
  models:
    primary: opus        # Claude Opus 4.6 (via claude.ai or API)
    secondary: gpt-5.3-codex  # OpenAI GPT-5.3-codex (via Responses API)

  # Consensus thresholds (0-1000 scale)
  thresholds:
    high_consensus: 700      # Both models > this = auto-integrate
    disputed_delta: 300      # Score delta > this = disputed
    low_value: 400           # Both < this = discard
    blocker_skeptic: 700     # Skeptic concern > this = blocker

  # Iteration safety cap — max Flatline loops before forced termination
  max_iterations: 5

  # Knowledge retrieval for domain context
  knowledge:
    # Tier 1: Local grimoires (always active)
    local:
      enabled: true
      paths:
        - grimoires/loa/
        - .claude/protocols/

    # Tier 2: NotebookLM (optional, requires browser auth setup)
    notebooklm:
      enabled: false           # Opt-in (requires auth setup)
      notebook_id: ""          # Your NotebookLM notebook ID
      timeout_ms: 30000        # Query timeout

  # Inquiry mode (FR-4): Collaborative multi-model architectural inquiry
  # Runs 3 parallel queries (structural, historical, governance) and synthesizes
  inquiry:
    budget_cents: 500            # Cost budget per inquiry invocation
    # Perspectives use primary/secondary/tertiary models with rotating assignment

  # Adversarial cross-model dissent for quality gates (#224)
  # A second model reviews code that Claude already reviewed
  code_review:
    enabled: false               # Opt-in: enable for /review-sprint
    model: "gpt-5.3-codex"      # Dissenter model
    timeout_seconds: 60          # Per-call timeout
    budget_cents: 150            # Max cost per dissent call
  security_audit:
    enabled: false               # Opt-in: enable for /audit-sprint
    model: "gpt-5.3-codex"      # Dissenter model
    timeout_seconds: 60
    budget_cents: 150
  stable_anchors:
    required: true               # Demote anchorless high-severity findings
    preferred_format: "symbol"   # symbol | hunk_header | line_number
    enforce_for: ["BLOCKING", "CRITICAL", "HIGH"]
  context_escalation:
    enabled: true                # Full-file context for P0 files
    secondary_token_budget: 15000
    max_file_lines: 500
    max_file_bytes: 51200        # 50KB
    denylist: ["*.pem", "*.key", "*.p12", "*.pfx", "id_rsa*", ".env*", "credentials.*", "secrets.*", "*.secret"]
  secret_scanning:
    enabled: true                # Pre-send redaction (recommended)
    patterns:                    # Format-specific regex patterns
      - "AKIA[0-9A-Z]{16}"
      - "-----BEGIN[A-Z ]*PRIVATE KEY-----"
      - "ghp_[A-Za-z0-9]{36}"
    allowlist:                   # False-positive exclusions
      - "sha256:[a-f0-9]{64}"
      - "[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}"

# -----------------------------------------------------------------------------
# Autonomous Flatline Mode (v1.22.0)
# -----------------------------------------------------------------------------
# Enable Flatline Protocol to operate within autonomous workflows (/autonomous,
# /run sprint-plan) without human intervention. HIGH_CONSENSUS findings auto-
# integrate, BLOCKERS halt workflow, DISPUTED items are logged for post-review.
autonomous_mode:
  # Master toggle - set to true to enable autonomous operation
  # Default: false (requires explicit opt-in for safety)
  enabled: false

  # Auto-enable when AI operator detected (CLAWDBOT_GATEWAY_TOKEN, LOA_OPERATOR=ai)
  # Only triggers on "strong" signals - weak signals require explicit enabled: true
  auto_enable_for_ai: true

  # Actions for each consensus category
  actions:
    high_consensus: integrate    # integrate | log | skip
    disputed: log                # halt | log | skip (logged to NOTES.md + trajectory)
    blocker: halt                # halt | log | continue (halt generates escalation)
    low_value: skip              # log | skip

  # Behavior on unrecoverable error (auth failure, invalid response, etc.)
  # halt: Stop workflow, generate escalation report
  # continue: Log error, skip document, continue with next
  on_error: halt

  # Maximum disputed items before converting to BLOCKER
  # Threshold scope determines if this is per-phase or cumulative
  # Default: 5 per phase
  max_disputed_items: 5

  # Disputed threshold configuration
  disputed:
    threshold_scope: per_phase   # per_phase | cumulative
    warn_at_percent: 60          # Warn at N% of threshold (e.g., 3/5)
    critical_at_percent: 80      # Escalate warning at N% (e.g., 4/5)

  # Timeout configuration (all values in milliseconds)
  timeouts:
    per_call: 60000              # Single API call timeout (60s)
    per_document: 180000         # Total time for one document review (3min)
    total_run: 900000            # Total time for all phases (15min)

  # Retry configuration for transient errors
  retry:
    max_attempts: 3              # Maximum retry attempts per call
    base_delay_ms: 1000          # Initial delay between retries
    max_delay_ms: 30000          # Maximum delay (with exponential backoff + jitter)

  # Pre-integration snapshot configuration
  snapshots:
    enabled: true                # Create snapshots before auto-integration
    max_age_days: 7              # Auto-cleanup snapshots older than this

    # Git integration (SECURITY: defaults to false to prevent history pollution)
    git_commit: false            # Commit snapshots to git (default: local only)
    git_commit_with_hooks: true  # Run pre-commit hooks when git_commit is true
    secret_scanning: true        # Scan for secrets before git commit (gitleaks/basic)

    # Storage quota management (prevents disk exhaustion)
    max_count: 100               # Maximum number of snapshots to retain
    max_bytes: 104857600         # Maximum total storage (100MB default)
    on_quota: fail               # fail | purge_oldest (what to do when quota exceeded)

  # Document/manifest locking (prevents concurrent modification)
  locking:
    enabled: true                # Enable flock()-based advisory locks
    timeout_seconds: 10          # Lock acquisition timeout
    stale_ttl_seconds: 300       # Auto-expire stale locks (5min)
    max_retries: 3               # Retry attempts with exponential backoff

    # Run-level isolation (prevents concurrent Flatline runs)
    run_isolation: true          # Acquire global run mutex before starting

    # NFS fallback (for shared filesystems where flock may not work)
    nfs_fallback: true           # Use mkdir-based atomic locking as fallback

# -----------------------------------------------------------------------------
# Autonomous Flatline Examples
# -----------------------------------------------------------------------------
# Example 1: Minimal (AI auto-enable, safe defaults)
# autonomous_mode:
#   enabled: false               # Let auto_enable_for_ai handle it
#   auto_enable_for_ai: true     # Enable when running under AI operator
#
# Example 2: Explicit autonomous with safety limits
# autonomous_mode:
#   enabled: true
#   max_disputed_items: 3        # Lower threshold for safety
#   timeouts:
#     total_run: 600000          # 10 minute limit
#   snapshots:
#     enabled: true
#     git_commit: false          # Local snapshots only
#
# Example 3: Conservative (log everything, no auto-integrate)
# autonomous_mode:
#   enabled: true
#   actions:
#     high_consensus: log        # Log instead of integrate
#     disputed: log
#     blocker: halt
#     low_value: log
#
# Example 4: Aggressive (continue on errors) - USE WITH CAUTION
# autonomous_mode:
#   enabled: true
#   on_error: continue           # Don't halt on errors
#   actions:
#     blocker: log               # Log blockers instead of halting
#   # WARNING: This may allow problematic changes to accumulate

# -----------------------------------------------------------------------------
# Eval Sandbox (v1.32.0)
# -----------------------------------------------------------------------------
# Configuration for the eval framework: deterministic framework evals and
# stochastic agent evals with baseline comparison and CI integration.
# See: evals/README.md for architecture and usage.
eval:
  # Default suite to run when no --suite specified
  default_suite: framework

  # Sandbox mode: local (default) or container (Docker)
  sandbox_mode: local

  # Trial configuration
  trials:
    # Default trials for framework evals (deterministic, 1 is sufficient)
    framework: 1
    # Default trials for agent evals (stochastic, 3+ recommended)
    agent: 3

  # Comparison thresholds
  comparison:
    # Regression threshold — pass rate drop larger than this triggers regression
    threshold: 0.10
    # Use Wilson confidence intervals for multi-trial comparisons
    wilson_ci: true
    # Model version skew makes results advisory-only
    advisory_on_model_skew: true

  # CI integration
  ci:
    # Post PR comment with eval results
    post_pr_comment: true
    # Block PR on regressions (exit code 1)
    block_on_regression: true
    # Allow infrastructure errors to pass (exit code 2)
    allow_infra_errors: true

  # Baseline management
  baselines:
    # Require --reason flag when updating baselines
    require_reason: true
    # Directory for baseline YAML files
    directory: evals/baselines

  # Result storage
  results:
    # JSONL ledger for historical results
    ledger: evals/results/eval-ledger.jsonl
    # Retention for CI artifacts (days)
    artifact_retention_days: 90

# =============================================================================
# Post-PR Validation Loop (v1.25.0)
# =============================================================================
# Automated validation after PR creation: audit, context clear, E2E, Flatline
# PRD: grimoires/loa/prd-post-pr-validation.md
# SDD: grimoires/loa/sdd-post-pr-validation.md
post_pr_validation:
  # Master toggle - set to false to disable all post-PR validation
  enabled: true

  # -------------------------------------------------------------------------
  # Phase Toggles
  # -------------------------------------------------------------------------
  phases:
    # Consolidated PR audit after PR creation
    audit:
      enabled: true
      # Maximum fix iterations before escalating
      max_iterations: 5
      # Skip findings below this severity
      min_severity: "medium"

    # Context clearing for fresh-eyes review
    context_clear:
      enabled: true
      # Write checkpoint to NOTES.md Session Continuity
      write_checkpoint: true

    # E2E testing with fresh context
    e2e:
      enabled: true
      # Maximum fix iterations
      max_iterations: 3
      # Build command (uses package.json scripts if not specified)
      # build_command: "npm run build"
      # Test command (uses package.json scripts if not specified)
      # test_command: "npm test"

    # Final Flatline PR review (optional, costs ~$1.50)
    flatline:
      enabled: false  # Disabled by default due to cost
      # Mode for Flatline review
      mode: "hitl"    # hitl | autonomous

  # -------------------------------------------------------------------------
  # Per-Phase Timeouts (seconds)
  # -------------------------------------------------------------------------
  timeouts:
    post_pr_audit: 600    # 10 minutes
    context_clear: 60     # 1 minute
    e2e_testing: 1200     # 20 minutes
    flatline_pr: 300      # 5 minutes

  # -------------------------------------------------------------------------
  # Circuit Breakers
  # -------------------------------------------------------------------------
  circuit_breaker:
    # Same finding appearing N times triggers escalation
    same_finding_threshold: 3
    # Same E2E failure appearing N times triggers escalation
    same_failure_threshold: 2

  # -------------------------------------------------------------------------
  # Marker Files (Flatline IMP-008)
  # -------------------------------------------------------------------------
  # Stored in .run/ directory with dotfile convention
  markers:
    audit_passed: ".PR-AUDITED"
    e2e_passed: ".PR-E2E-PASSED"
    validated: ".PR-VALIDATED"

  # -------------------------------------------------------------------------
  # GitHub API Retry Policy (Flatline IMP-003)
  # -------------------------------------------------------------------------
  github_api:
    max_attempts: 3
    # Exponential backoff delays (seconds)
    backoff: [1, 2, 4]
    # Timeout per attempt (seconds)
    timeout_per_attempt: 30

  # -------------------------------------------------------------------------
  # Integration with Run Mode
  # -------------------------------------------------------------------------
  # When run_mode creates a PR, automatically invoke post-PR validation
  auto_invoke:
    enabled: true
    # Mode for auto-invoked validation
    mode: "autonomous"

# =============================================================================
# Run Bridge — Autonomous Excellence Loop (v1.34.0)
# =============================================================================
# Iterative sprint-plan → Bridgebuilder review → findings → repeat loop.
# Each iteration leaves a GitHub trail and captures visions.
run_bridge:
  # Master toggle — must be true to use /run-bridge
  enabled: false

  # ── Quick Start Profiles ──
  # Minimal (convergence only): enabled: true — all sub-features default false
  # Standard (+ cross-repo + lore): also set cross_repo_query.enabled: true
  # Exploration (all features):  also set research_mode.enabled: true,
  #   research_mode.inquiry_enabled: true, vision_registry.activation_enabled: true

  # Default parameters
  defaults:
    # Maximum bridge iterations (1-5)
    depth: 3
    # Review after each sprint vs full plan
    per_sprint: false
    # Flatline threshold: ratio of current/initial score below which to count as "flat"
    flatline_threshold: 0.05
    # How many consecutive below-threshold iterations before stopping
    consecutive_flatline: 2

  # Timeout limits
  timeouts:
    # Maximum hours per bridge iteration
    per_iteration_hours: 4
    # Maximum total hours for entire bridge run
    total_hours: 24

  # GitHub trail configuration
  github_trail:
    # Post Bridgebuilder review as PR comment after each iteration
    post_comments: true
    # Update PR body with iteration summary table
    update_pr_body: true
    # Commit message prefix for bridge iteration commits
    commit_prefix: "bridge"

  # Ground Truth generation
  ground_truth:
    enabled: true
    # Max tokens per GT section file
    max_tokens_per_section: 2000
    # Max tokens for GT index file
    index_max_tokens: 500

  # Vision Registry
  vision_registry:
    enabled: true
    # Auto-capture VISION findings from Bridgebuilder reviews
    auto_capture: true
    # FR-3: Activate relevant visions during bridge cycles (scan for tag overlap)
    activation_enabled: false

  # RTFM documentation gate (runs after loop termination)
  rtfm:
    enabled: true
    # Maximum fix iterations on RTFM failure (capped to prevent loops)
    max_fix_iterations: 1

  # Lore integration
  lore:
    enabled: true
    # Which lore categories to load for bridge context
    categories:
      - mibera
      - neuromancer

  # Bridgebuilder persona enrichment (v1.35.0)
  bridgebuilder:
    # Enable persona-driven enriched reviews
    persona_enabled: true
    # Path to persona definition file
    persona_path: .claude/data/bridgebuilder-persona.md
    # Include enriched fields (faang_parallel, metaphor, teachable_moment, connection)
    enriched_findings: true
    # Generate insights stream (rich prose surrounding findings)
    insights_stream: true
    # Include PRAISE severity findings for good engineering decisions
    praise_findings: true
    # Verify persona file integrity against base branch
    integrity_check: true
    # Token budget for review output
    token_budget:
      # Maximum tokens for findings JSON stream
      findings_tokens: 5000
      # Maximum tokens for insights prose stream
      insights_tokens: 25000
      # Maximum total tokens (both streams)
      total_tokens: 30000
    # Size limits for PR comments
    size_limits:
      # Truncate preserving findings JSON (65KB)
      truncate_bytes: 66560
      # Findings-only emergency fallback (256KB)
      findings_only_bytes: 262144
    # Security content redaction
    redaction:
      # Enable gitleaks-inspired pattern redaction
      enabled: true
      # Block posting if secrets remain after redaction
      post_redaction_safety: true

  # Cross-Repository Pattern Query (FR-1, v1.40.0)
  # Discovers structural parallels across sibling repos before each bridge review.
  # Resolution: sibling directory → config override → REMOTE: GitHub API fallback.
  cross_repo_query:
    enabled: false                  # Enable cross-repo pattern matching
    # ecosystem:                    # Override auto-discovery of sibling repos
    #   - /path/to/sibling-repo
    #   - REMOTE:0xHoneyJar/loa-hounfour
    budget: 2000                    # Token budget per repo query
    max_repos: 5                    # Maximum repos to query per iteration
    per_repo_timeout: 5             # Per-repo timeout (seconds)
    timeout: 15                     # Total timeout for all queries (seconds)

  # Research Mode (FR-2, v1.40.0) — Divergent Exploration Iterations
  # After convergence iterations, optionally run a divergent exploration that
  # produces SPECULATION-only findings excluded from flatline scoring.
  research_mode:
    enabled: false                  # Enable research mode
    trigger_after_iteration: 1      # Fire after N convergent iterations complete
    max_research_iterations: 1      # Maximum research iterations per bridge run
    inquiry_enabled: false          # Also trigger multi-model inquiry (FR-4)

# =============================================================================
# Agent Teams Compatibility (v1.39.0)
# =============================================================================
# Experimental: Requires CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1
# Enables multi-agent orchestration with Loa's workflow.
# See: .claude/loa/reference/agent-teams-reference.md
agent_teams:
  # Detection mode: auto (use if available), true (require), false (disable)
  enabled: auto

  # Beads access model: Only the team lead runs br commands;
  # teammates report task status via SendMessage
  beads_access: lead_only

  # State file behavior when Agent Teams is active
  state_files:
    # Use teammate-scoped state files (.run/*.{name}.json)
    scoped: true
    # Lead merges teammate state into canonical files on TeamDelete
    merge_on_shutdown: true

# =============================================================================
# Post-Merge Automation Pipeline (v1.36.0)
# =============================================================================
# Automated post-merge pipeline triggered on push to main.
# 3-layer architecture: GH Actions → claude-code-action → shell orchestrator.
post_merge:
  # Master toggle — must be true for GH Actions workflow to process merges
  enabled: false

  # Phase matrix for each PR type
  # cycle: all 8 phases (classify, semver, changelog, gt_regen, rtfm, tag, release, notify)
  # bugfix: 4 phases (classify, semver, tag, notify)
  # other: 4 phases (classify, semver, tag, notify)

  # claude-code-action configuration
  claude_code_action:
    # Model for cycle pipeline execution
    model: "claude-sonnet-4-5-20250929"
    # Maximum conversation turns
    max_turns: 15
    # Tool allowlist
    allowed_tools: "Bash(bash),Read,Write,Glob,Grep"

  # Timeouts
  timeouts:
    # Full pipeline timeout in minutes (GH Actions job timeout)
    full_pipeline_minutes: 30

  # Phase-specific options
  phases:
    # Skip ground truth regeneration
    skip_gt: false
    # Skip RTFM validation
    skip_rtfm: false

  # Notification
  notify:
    # Post pipeline summary as PR comment
    pr_comment: true
    # Discord notification on failure (requires DISCORD_WEBHOOK_URL secret)
    discord_on_failure: true

# =============================================================================
# Harness Engineering — Safety Hooks, Deny Rules, Audit (v1.37.0)
# =============================================================================
# Defense-in-depth configuration for agent safety. Hooks operate at the Claude
# Code platform level, providing protection across all modes (interactive,
# autonomous, simstim). Source: Trail of Bits + OpenAI harness patterns.
harness:
  # Safety hooks — PreToolUse:Bash destructive command blocking
  safety_hooks:
    enabled: true                         # Master toggle for safety hook
    # Individual pattern toggles (all true by default)
    block_rm_rf: true                     # Block rm -rf (suggest trash)
    block_force_push: true                # Block git push --force (suggest --force-with-lease)
    block_reset_hard: true                # Block git reset --hard (suggest git stash)
    block_git_clean: true                 # Block git clean -f without -n dry-run

  # Deny rules — platform-level file access blocking
  deny_rules:
    # Auto-install during /mount (blocks ~/.ssh, ~/.aws, ~/.kube, etc.)
    auto_install: true                    # Set false to skip during /mount
    # Template: .claude/hooks/settings.deny.json
    # Installer: .claude/scripts/install-deny-rules.sh

  # Audit logging — PostToolUse:Bash mutation logger
  audit_logging:
    enabled: true                         # Log mutating commands to .run/audit.jsonl
    max_file_size_mb: 10                  # Rotate when audit log exceeds this size

  # Stop guard — prevent premature exit during autonomous runs
  stop_guard:
    enabled: true                         # Check for active /run, /run-bridge, /simstim

  # Invariant linter — mechanical validation of Loa structure
  invariant_linting:
    enabled: true                         # Enable lint-invariants.sh
    on_mount: true                        # Run after /mount
    on_run_preflight: true                # Run during /run preflight

# =============================================================================
# Bridgebuilder — Autonomous PR Review
# =============================================================================
# Configuration for the /bridgebuilder skill. All fields have sensible defaults.
# Precedence: CLI flags > env vars > this config > auto-detect > built-in defaults.
bridgebuilder:
  # Master toggle — set to false to disable the skill entirely
  enabled: true

  # Additional repositories to review (owner/repo format).
  # Auto-detected repo from git remote is always included unless --no-auto-detect.
  # Env: BRIDGEBUILDER_REPOS (comma-separated)
  repos: []

  # LLM model for generating reviews.
  # Env: BRIDGEBUILDER_MODEL
  model: "claude-sonnet-4-5-20250929"

  # Maximum open PRs to process per run
  max_prs: 10

  # Maximum files per PR (excess truncated, risk-prioritized: security files first)
  max_files_per_pr: 50

  # Maximum diff size in bytes (100KB default)
  max_diff_bytes: 100000

  # Token budget for LLM input (persona + diff + metadata)
  max_input_tokens: 8000

  # Maximum response tokens for generated review
  max_output_tokens: 4000

  # Review dimensions (subset of: security, quality, test-coverage, operational-readiness)
  dimensions:
    - security
    - quality
    - test-coverage

  # HTML comment marker for idempotency detection
  review_marker: "bridgebuilder-review"

  # Path to persona override (project-specific reviewer personality).
  # Falls back to built-in resources/BEAUVOIR.md if file not found.
  persona_path: "grimoires/bridgebuilder/BEAUVOIR.md"

# =============================================================================
# QMD Context Query — Unified context retrieval with three-tier fallback
# =============================================================================
# Controls the qmd-context-query.sh script that provides semantic search
# across grimoires, skills, notes, and reality files.
# Three-tier fallback: QMD (semantic) → CK (code knowledge) → grep (text)

qmd_context:
  # Master switch — set to false to disable all context injection
  enabled: true

  # Default token budget for context results (word_count × 1.3)
  default_budget: 2000

  # Timeout in seconds for each search tier
  timeout_seconds: 5

  # Scope definitions — map scope names to backend-specific paths
  scopes:
    grimoires:
      qmd_collection: "loa-grimoire"
      ck_path: ".ck/loa-grimoire/"
      grep_paths:
        - "grimoires/loa/"
    skills:
      qmd_collection: "loa-skills"
      ck_path: ".ck/skills/"
      grep_paths:
        - ".claude/skills/"
    notes:
      qmd_collection: "loa-grimoire"
      ck_path: ".ck/loa-grimoire/"
      grep_paths:
        - "grimoires/loa/NOTES.md"
    reality:
      qmd_collection: "loa-reality"
      ck_path: ".ck/reality/"
      grep_paths:
        - "grimoires/loa/reality/"

  # Per-skill budget and scope overrides
  # Keys match the --skill argument passed by each SKILL.md integration:
  #   implement      → /implement (implementing-tasks/SKILL.md)
  #   review_sprint  → /review-sprint (reviewing-code/SKILL.md)
  #   ride           → /ride (riding-codebase/SKILL.md)
  #   run_bridge     → /run-bridge (bridge-orchestrator.sh)
  #   gate0          → preflight.sh run_integrity_checks()
  skill_overrides:
    implement:
      budget: 2000
      scope: grimoires
    review_sprint:
      budget: 1500
      scope: grimoires
    ride:
      budget: 2000
      scope: reality
    run_bridge:
      budget: 2500
      scope: grimoires
    gate0:
      budget: 1000
      scope: notes
